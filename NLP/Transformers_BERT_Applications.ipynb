{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTqj7mNFciWz"
   },
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ = \"sentiment-analysis\"\n",
    "def get_sentiment(text, model, tokenizer, task=task_):\n",
    "  pipe = pipeline(task=task, model=model, tokenizer=tokenizer)\n",
    "  sentiment_result = pipe(text)\n",
    "  return sentiment_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['Your tone in written communication can be fair formal.',\n",
    "        'You often fail to follow up with customers as promised.',\n",
    "        'Your tone in written communication is too offensive.',\n",
    "        'I hate your production',\n",
    "        'من این فیلم رو دوست نداشتم']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '4 stars', 'score': 0.37983793020248413},\n",
       " {'label': '4 stars', 'score': 0.3468973636627197},\n",
       " {'label': '2 stars', 'score': 0.47493189573287964},\n",
       " {'label': '1 star', 'score': 0.8062731027603149},\n",
       " {'label': '1 star', 'score': 0.42411860823631287}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment(text, model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI_tjsQLcmqz"
   },
   "source": [
    "## Name Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification\n",
    "task_ = 'ner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner_results(text, model, tokenizer, task=task_):\n",
    "    nlp = pipeline(task, model=model, tokenizer=tokenizer)\n",
    "    ner_results = nlp(text)\n",
    "    # Calculate the character start and end positions of each entity manually\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    offset = 0  # Offset to track character positions in the original text\n",
    "    updated_results = []\n",
    "    for result in ner_results:\n",
    "        word = result['word'].lstrip(\"##\")  # Remove subword prefix if present\n",
    "        start = text.find(word, offset)\n",
    "        end = start + len(word)\n",
    "        if start != -1:  # Only update if the word was found\n",
    "            result['start'] = start\n",
    "            result['end'] = end\n",
    "            updated_results.append(result)\n",
    "            offset = end  # Update offset to next possible start position\n",
    "    return updated_results\n",
    "\n",
    "def highlight_entities(text, ner_results):\n",
    "    highlighted_text = text\n",
    "    # Reverse sort by start index to not mess up the indices when adding brackets\n",
    "    for entity in sorted(ner_results, key=lambda x: x['start'], reverse=True):\n",
    "        start, end = entity['start'], entity['end']\n",
    "        highlighted_text = highlighted_text[:end] + \"]\" + highlighted_text[end:]\n",
    "        highlighted_text = highlighted_text[:start] + \"[\" + highlighted_text[start:]\n",
    "    return highlighted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForTokenClassification.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[Barack] [Obama] was born in [Hawaii], 1955, worked at [Google]. He served as the president of the [United] [States].'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Barack Obama was born in Hawaii, 1955, worked at Google. He served as the president of the United States.\"\n",
    "ner_result = get_ner_results(text, model, tokenizer)\n",
    "highlight_entities(text, ner_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUvpygB6g-05"
   },
   "source": [
    "## Text Summarization\n",
    " in this task there is a kind of encoding and text generation, so BERT is not suitable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(text, model, tokenizer, max_len, min_len):\n",
    "  summarizer = pipeline(task='summarization', model=model, tokenizer=tokenizer)\n",
    "  summary = summarizer(text, max_length=max_len, min_length=min_len)\n",
    "  return summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7408526865ef48a1ade7ea3a25c15f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead713729ffb489e9e91ddcc6c909e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00ddcd2a8704c94b57031afd818818d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1ea92d65194a3ea6a8dfe313119dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ff0a27151a4b22b37a349547895cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba2b28f43114845a1889804237633a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gutenberg Bible is an edition of\n",
      "1035\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "text = \"The Gutenberg Bible, also known as the 42-line Bible, the Mazarin Bible or the B42, was the earliest major book printed in Europe using mass-produced metal movable type. It marked the start of the \\\"Gutenberg Revolution\\\" and the age of printed books in the West. The book is valued and revered for its high aesthetic and artistic qualities[1] and its historical significance. The Gutenberg Bible is an edition of the Latin Vulgate printed in the 1450s by Johannes Gutenberg in Mainz, in present-day Germany. Forty-nine copies (or substantial portions of copies) have survived. They are thought to be among the world's most valuable books, although no complete copy has been sold since 1978.[2][3] In March 1455, the future Pope Pius II wrote that he had seen pages from the Gutenberg Bible displayed in Frankfurt to promote the edition, and that either 158 or 180 copies had been printed. The 36-line Bible, said to be the second printed Bible, is also sometimes referred to as a Gutenberg Bible, but may be the work of another printer.\"\n",
    "summary = get_summary(text, model, tokenizer, max_len=10, min_len=2)\n",
    "print(summary)\n",
    "print(len(text))\n",
    "print(len(summary))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
