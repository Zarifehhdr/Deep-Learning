Generative Adversarial Nets (GANs)

This repository contains implementations and experiments for Generative Adversarial Networks (GANs) as part of the Deep-Learning series. GANs are powerful generative models that learn to produce realistic synthetic data by training two neural networks in opposition: a generator and a discriminator.

This project serves as both a learning resource and a foundation for advanced generative deep learning research and real-world applications.

Table of Contents

About

Key Features

Getting Started

Installation Instructions

Usage and Examples

Results and Visualizations

Project Structure

Contributing

License

Contact

About

Generative Adversarial Networks (GANs) are a class of generative models introduced in 2014 that have significantly advanced image synthesis, data augmentation, and unsupervised representation learning.

A GAN consists of two neural networks trained in an adversarial setup:

Generator: Learns to produce synthetic samples that resemble real data.
Discriminator: Learns to distinguish real samples from synthetic ones.

Through this competitive training process, the generator progressively improves its outputs until they become highly realistic.

This repository focuses on core GAN implementations, structured training pipelines, and reproducible experimentation.

Key Features

Clean and modular implementation of GAN architecture
Configurable training pipeline with adjustable hyperparameters
Support for common benchmark datasets
Visualization of generated outputs during training
Structured codebase ready for extension to advanced GAN variants

Getting Started

Follow the steps below to run the project locally.

Requirements

Python 3.8 or higher
PyTorch
torchvision
NumPy
Matplotlib
Optional: CUDA-enabled GPU for faster training

Installation Instructions

Clone the repository:

git clone https://github.com/Zarifehhdr/Deep-Learning.git

Navigate to the GAN directory:

cd Deep-Learning/Generative_Adversarial_Nets

Install dependencies:

pip install -r requirements.txt

If a requirements file is not included, install the necessary libraries manually.

Usage and Examples

Training

To train the GAN model on a dataset such as MNIST:

python train.py --dataset MNIST --epochs 100 --batch_size 64

You can modify hyperparameters such as learning rate, batch size, or number of epochs to experiment with model performance.

Inference and Sample Generation

After training, generate new synthetic samples using:

python generate.py --model_path checkpoints/generator.pth --num_samples 100

Generated images will be saved in the output directory.

Results and Visualizations

This section can include:

Generated sample grids after training
Loss curves for generator and discriminator
Training progression visualizations

Including visual results provides immediate insight into model quality and convergence behavior.

Project Structure

Generative_Adversarial_Nets/
data/ – Dataset storage
models/ – Generator and discriminator implementations
train.py – Training script
generate.py – Sample generation script
utils.py – Helper functions
requirements.txt – Project dependencies
output/ – Generated samples and visualizations

Each module is structured to maintain clarity, scalability, and ease of experimentation.

Contributing

Contributions are welcome. Suggestions for improvement include:

Adding conditional GAN implementation
Integrating advanced variants such as DCGAN, WGAN, or StyleGAN
Adding evaluation metrics such as FID or Inception Score
Improving experiment tracking and logging

Feel free to open issues or submit pull requests.

License

This project is released under the MIT License.

Contact

For collaboration, research discussions, or feedback:

GitHub: https://github.com/Zarifehhdr

Email: zah47@pitt.edu
